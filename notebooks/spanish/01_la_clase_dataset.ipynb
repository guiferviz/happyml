{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La clase DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos empezar a entrenar algoritmos lo primero que necesitamos son datos. La mayoría de las veces tendremos los datos guardados en archivos externos en diferentes formatos. Como inversión para el futuro vamos a crear una forma fácil de cargar y manipular datos para que posteriormente los algoritmos de nuestra librería `HappyML` los usen.\n",
    "\n",
    "En este primer notebook vamos a crear una clase llamada `DataSet` que se encargará de encapsular nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Un poco de matemáticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar definiremos matemáticamente qué es un **dataset** $\\mathcal{D}$.\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = (\\mathbf{x}_1, \\mathbf{y}_1), (\\mathbf{x}_2, \\mathbf{y}_2), \\dots, (\\mathbf{x}_N, \\mathbf{y}_N)\n",
    "$$\n",
    "\n",
    "en el que el $\\mathbf{x}_i$ es el vector de entrada del ejemplo $i$ y $\\mathbf{y}_i$ es el vector de salida asociado al ejemplo $i$. Dichos vectores se definen como\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_d \\end{bmatrix} \\in \\mathbb{R}^d\n",
    ", \\qquad\n",
    "\\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_k \\end{bmatrix} \\in \\mathbb{R}^k\n",
    ".\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos simplificar el concepto de dataset si juntamos los datos de entrada en una matriz y los de salida en otra.\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "- & \\mathbf{x}_1^\\mathrm{T} & - \\\\\n",
    "- & \\mathbf{x}_2^\\mathrm{T} & - \\\\\n",
    "  & \\vdots       &   \\\\\n",
    "- & \\mathbf{x}_N^\\mathrm{T} & - \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{N \\times d}\n",
    ", \\qquad\n",
    "\\mathbf{Y} = \\begin{bmatrix}\n",
    "- & \\mathbf{y}_1^\\mathrm{T} & - \\\\\n",
    "- & \\mathbf{y}_2^\\mathrm{T} & - \\\\\n",
    "  & \\vdots       &   \\\\\n",
    "- & \\mathbf{y}_N^\\mathrm{T} & - \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{N \\times k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando clase DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestra implementación almacenaremos los datos usando matrices. Esta forma de hacerlo mejora la eficiencia de cualquier operación que queramos realizar con los datos. Las operaciones matriciales son altamente paralelizables. `numpy` se encargará de paralelizar los cálculos por nosotros simplificándonos mucho la vida. A partir de ahora, siempre que podamos usaremos operaciones con matrices en lugar de realizar bucles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DataSet():\n",
    "    \"\"\"Generic collection of inputs and outputs.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    X = np.empty((0, 0))\n",
    "\n",
    "    Y = np.empty((0, 0))\n",
    "\n",
    "\n",
    "    def get_N(self):\n",
    "        \"\"\"Gets the number of samples in the dataset.\n",
    "        \n",
    "        \"\"\"\n",
    "        # The next two expressions are not necessarily equivalent:\n",
    "        # self.X.shape[0] and self.Y.shape[0]\n",
    "        # self.Y.shape[0] <-- Can be 0 if no output assigned.\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def get_d(self):\n",
    "        \"\"\"Gets the dimension of each sample in the dataset.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    def get_k(self):\n",
    "        \"\"\"Gets the number of outputs of each sample.\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.Y.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leyendo ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si creamos un objeto de la clase `DataSet` contendrá dos matrices vacías. Vamos a añadir un par de métodos auxiliares que nos permitan rellenar esas matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load(filename, delimiter=\"\", n_outputs=1, one_shot_output=False, header=False):\n",
    "    # Set delimiters if filename has a know extension.\n",
    "    if delimiter is \"\":\n",
    "        if filename.endswith(\".csv\"):\n",
    "            delimiter = \",\"\n",
    "        else:\n",
    "            delimiter = None\n",
    "    # Open file and load dataset from stream.\n",
    "    return load_from_stream(open(filename), delimiter=delimiter, n_outputs=n_outputs,\n",
    "                            one_shot_output=one_shot_output, header=header)\n",
    "\n",
    "\n",
    "def load_from_stream(stream, delimiter=\",\", n_outputs=1,\n",
    "                     one_shot_output=False, header=False):\n",
    "    # Check parameters.\n",
    "    assert not (one_shot_output and abs(n_outputs) != 1), \\\n",
    "        \"If one-shot output is selected the number of outputs must be 1.\"\n",
    "    # Read stream.\n",
    "    data = np.loadtxt(stream, delimiter=delimiter, skiprows=int(header))\n",
    "    # Check feature dimensions.\n",
    "    d = data.shape[1]\n",
    "    assert d >= abs(n_outputs), \\\n",
    "        \"Number of outputs greater than number of data columns.\"\n",
    "    # Set starts/ends of the submatrixes X and Y.\n",
    "    if n_outputs <= 0:\n",
    "        start_X = 0\n",
    "        end_X = start_Y = d + n_outputs\n",
    "        end_Y = d\n",
    "    else:\n",
    "        start_Y = 0\n",
    "        end_Y = start_X = n_outputs\n",
    "        end_X = d\n",
    "    # Create DataSet object.\n",
    "    dataset = DataSet()\n",
    "    dataset.X = data[:, start_X:end_X]\n",
    "    dataset.Y = data[:, start_Y:end_Y]\n",
    "    if one_shot_output:\n",
    "        max_output = dataset.Y.max()\n",
    "        min_output = dataset.Y.min()\n",
    "        N = dataset.get_N()\n",
    "        k = max_output - min_output + 1\n",
    "        indexes = np.add(dataset.Y, -min_output)\n",
    "        indexes = indexes.astype(int).reshape(N)\n",
    "        dataset.Y = np.zeros((N, k))\n",
    "        dataset.Y[np.arange(0, N), indexes] = 1\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos de hacer es crear un archivo con un dataset de pruebas. Comprobamos que está correctamente guardado y mostramos su contenido. Como puede observarse está en formato CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,1\n",
      "1,-1,1\n",
      "-1,1,-1\n",
      "-1,-1,-1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../resources/dataset01.csv\"\n",
    "str = open(filename).read()\n",
    "print str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a cargarlo usando nuestro método `load`. Por defecto se toma la primera columna como si fuera el valor de salida $\\mathbf{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[ 1.  1.]\n",
      " [ 1. -1.]\n",
      " [-1.  1.]\n",
      " [-1. -1.]]\n",
      "Y:\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "N: 4\n",
      "d: 2\n",
      "k: 1\n"
     ]
    }
   ],
   "source": [
    "dataset = load(filename)\n",
    "\n",
    "print \"X:\\n\", dataset.X\n",
    "print \"Y:\\n\", dataset.Y\n",
    "print \"N:\", dataset.get_N()\n",
    "print \"d:\", dataset.get_d()\n",
    "print \"k:\", dataset.get_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 4\n",
      "d: 1\n",
      "k: 2\n"
     ]
    }
   ],
   "source": [
    "dataset = load(filename, n_outputs=2)\n",
    "\n",
    "print \"N:\", dataset.get_N()\n",
    "print \"d:\", dataset.get_d()\n",
    "print \"k:\", dataset.get_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 4\n",
      "d: 3\n",
      "k: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = load(filename, n_outputs=0)\n",
    "\n",
    "print \"N:\", dataset.get_N()\n",
    "print \"d:\", dataset.get_d()\n",
    "print \"k:\", dataset.get_k()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Guardando DataSets en archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo con ayuda de *numpy* vamos a crear una función que nos guarde un objeto `DataSet` en el disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def save(file, dataset, delimiter=\",\", header=\"\", footer=\"\"):\n",
    "    data = np.column_stack((dataset.Y, dataset.X))\n",
    "    np.savetxt(file, data, delimiter=delimiter, header=header, footer=footer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si por algún motivo se deseara imprimir por la terminal el valor del `DataSet` bastaría con llamar a la función `save` con `sys.stdout` como primer parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000000000000000e+00,1.000000000000000000e+00,1.000000000000000000e+00\n",
      "1.000000000000000000e+00,-1.000000000000000000e+00,1.000000000000000000e+00\n",
      "-1.000000000000000000e+00,1.000000000000000000e+00,-1.000000000000000000e+00\n",
      "-1.000000000000000000e+00,-1.000000000000000000e+00,-1.000000000000000000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "filename = \"../resources/dataset01.csv\"\n",
    "dataset = load(filename)\n",
    "save(sys.stdout, dataset)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
